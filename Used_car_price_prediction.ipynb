{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HJPRHN-A-dnS"
      },
      "outputs": [],
      "source": [
        "#IMPORTS\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jFYlebcPRK2K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "023072d9-2aa6-4089-83bf-c3ff823ded1f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a66faca0d7fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#UPLOADING DATA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vehicles.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: EOF inside string starting at row 419438"
          ]
        }
      ],
      "source": [
        "#UPLOADING DATA\n",
        "data = pd.read_csv(\"vehicles.csv\")\n",
        "ds=data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imtqz99xur2h"
      },
      "source": [
        "# **PROBLEM STATEMENT:**\n",
        "\n",
        "Create a ML model which can predict the Price of a used car\n",
        "\n",
        "Target Variable: Price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVg6vOyRRWvO"
      },
      "source": [
        "# **EXPLORATORY DATA ANALYSIS**\n",
        "\n",
        "Understanding the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdxZjZSnvbyQ"
      },
      "source": [
        "# **DATA EXPLORATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "288MbeKVvefu"
      },
      "outputs": [],
      "source": [
        "#Rows of the data\n",
        "ds.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-OGr-O2vqdZ"
      },
      "outputs": [],
      "source": [
        "#Data types\n",
        "ds.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRWNuwtOvrqk"
      },
      "outputs": [],
      "source": [
        "#Decription\n",
        "ds.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6HtkVA8vtK9"
      },
      "outputs": [],
      "source": [
        "#Unique values\n",
        "ds.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8EGp_TtwHaR"
      },
      "source": [
        "# **EXPLORATION RESULTS:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5njuiSt_ifd"
      },
      "source": [
        "**Columns:**\n",
        "\n",
        "- id              : Not required\n",
        "- url             : Not required\n",
        "- region          : Not required\n",
        "- region_url      : Not required\n",
        "- price           : **Target variable**\n",
        "- year           \n",
        "- manufacturer    \n",
        "- model          \n",
        "- condition       \n",
        "- cylinders       \n",
        "- fuel            \n",
        "- odometer        \n",
        "- title_status    \n",
        "- transmission    \n",
        "- VIN             : Not required\n",
        "- drive           \n",
        "- size            \n",
        "- type            \n",
        "- paint_color     \n",
        "- image_url       : Not required\n",
        "- description     : Not required\n",
        "- county          : Not required\n",
        "- state           \n",
        "- lat             : Not required\n",
        "- long            : Not required\n",
        "- posting_date    : Not required\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h--L8s9_hwlf"
      },
      "outputs": [],
      "source": [
        "#Finding the age of the car\n",
        "ds['car_age'] = 2022 - ds['year']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f08Wp6_oCC6b"
      },
      "outputs": [],
      "source": [
        "#Droping values not required\n",
        "ds = ds.drop(['id', 'url', 'region', 'region_url', 'year', 'VIN',  'image_url', 'description', 'county','lat', 'long', 'posting_date'], axis=1)\n",
        "#ds = ds.drop(['id', 'url', 'region', 'region_url', 'year', 'model', 'VIN', 'paint_color', 'image_url', 'description', 'county','lat', 'long', 'posting_date'], axis=1)\n",
        "ds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meXrbTbyjtpk"
      },
      "outputs": [],
      "source": [
        "ds.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhQ-xb9No-aq"
      },
      "source": [
        "- 'price' : continuous\n",
        "- 'manufacturer' : categorical\n",
        "- 'condition': categorical\n",
        "- 'cylinders': categorical\n",
        "- 'fuel': categorical\n",
        "- 'odometer': continuous\n",
        "- 'title_status': categorical\n",
        "- 'transmission': categorical \n",
        "- 'drive': categorical\n",
        "- 'size':categorical \n",
        "- 'type': categorical\n",
        "- 'state': categorical\n",
        "- 'car_age': categorical\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJL9BJtkuaR4"
      },
      "outputs": [],
      "source": [
        "print(\"Before dropping duplicates:\",ds.shape)\n",
        "ds=ds.drop_duplicates()\n",
        "print(\"Before dropping duplicates:\",ds.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2Xeb1UQBuJY"
      },
      "source": [
        "# **VISUAL EXPLORATORY DATA ANALYSIS**\n",
        "- Categorical variables: Bar plot\n",
        "- Continuous variables: Histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVazHgHfyTV1"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "#Continuous data\n",
        "ds.hist(['price','odometer'], figsize=(8,8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFdN4b7yBDqh"
      },
      "outputs": [],
      "source": [
        "#Categorical\n",
        "def PlotBarCharts(inpData, colsToPlot):\n",
        "    %matplotlib inline\n",
        "    \n",
        "    import matplotlib.pyplot as plt\n",
        "   \n",
        "    fig, subPlot=plt.subplots(nrows=1, ncols=len(colsToPlot), figsize=(20,5))\n",
        "    fig.suptitle('Bar charts of: '+ str(colsToPlot))\n",
        "\n",
        "    for colName, plotNumber in zip(colsToPlot, range(len(colsToPlot))):\n",
        "        inpData.groupby(colName).size().plot(kind='bar',ax=subPlot[plotNumber])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNKQBj6IB4OG"
      },
      "outputs": [],
      "source": [
        "PlotBarCharts(inpData=ds, colsToPlot=['car_age','manufacturer', 'condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'size', 'type', 'state','paint_color']) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56x8xcnCEZAA"
      },
      "source": [
        "Since all graphsother than title_status have comparable frequencies we consider them. We have to further analyize title_status"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoZwsh4xFiDq"
      },
      "source": [
        "# **OUTILER TREATMENT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqZjnFkVH-Sw"
      },
      "source": [
        "Since data distribution is skewed we use IQR based filtering"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,8))\n",
        "plt.subplot(2,2,1)\n",
        "sns.distplot(ds['price'])\n",
        "plt.subplot(2,2,2)\n",
        "sns.boxplot(ds['price'])\n",
        "plt.subplot(2,2,3)\n",
        "sns.distplot(ds['odometer'])\n",
        "plt.subplot(2,2,4)\n",
        "sns.boxplot(ds['odometer'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "npzJrup8B-RU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laQbuDhKGYxQ"
      },
      "outputs": [],
      "source": [
        "#Finding IQR\n",
        "q1 = ds['price'].quantile(0.25)\n",
        "q3 = ds['price'].quantile(0.75)\n",
        "\n",
        "#iqr\n",
        "iqr=q3-q1\n",
        "\n",
        "#finding upper and lower limit\n",
        "upper_limit = q3 + 1.5 * iqr\n",
        "lower_limit = q1 - 1.5 * iqr\n",
        "\n",
        "#Finding outlier\n",
        "ds[ds['price'] > upper_limit]\n",
        "ds[ds['price'] < lower_limit]\n",
        "\n",
        "\n",
        "#Triming\n",
        "df = ds[ds['price'] < upper_limit]\n",
        "\n",
        "#Visualization\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.subplot(2,2,1)\n",
        "sns.distplot(ds['price'])\n",
        "plt.subplot(2,2,2)\n",
        "sns.boxplot(ds['price'])\n",
        "plt.subplot(2,2,3)\n",
        "sns.distplot(df['price'])\n",
        "plt.subplot(2,2,4)\n",
        "sns.boxplot(df['price'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "upper_limit = df['price'].quantile(0.99)\n",
        "lower_limit = df['price'].quantile(0.10)\n",
        "print(upper_limit)\n",
        "print(lower_limit)\n",
        "new_df = df[(df['price'] <= 51721.0) & (df['price'] >= lower_limit)]"
      ],
      "metadata": {
        "id": "DykB1CMcHF3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualization\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.subplot(2,2,1)\n",
        "sns.distplot(df['price'])\n",
        "plt.subplot(2,2,2)\n",
        "sns.boxplot(df['price'])\n",
        "plt.subplot(2,2,3)\n",
        "sns.distplot(new_df['price'])\n",
        "plt.subplot(2,2,4)\n",
        "sns.boxplot(new_df['price'])\n",
        "plt.show()\n",
        "df=new_df"
      ],
      "metadata": {
        "id": "holTvalPZ5-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLB27curHx6j"
      },
      "outputs": [],
      "source": [
        "#ODOMETER\n",
        "#Finding IQR\n",
        "q1 = df['odometer'].quantile(0.25)\n",
        "q3 = df['odometer'].quantile(0.75)\n",
        "\n",
        "#iqr\n",
        "iqr=q3-q1\n",
        "\n",
        "#finding upper and lower limit\n",
        "upper_limit = q3 + 1.5 * iqr\n",
        "lower_limit = q1 - 1.5 * iqr\n",
        "\n",
        "#Finding outlier\n",
        "df[df['odometer'] > upper_limit]\n",
        "df[df['odometer'] < lower_limit]\n",
        "\n",
        "\n",
        "#Triming\n",
        "ds_final = df[df['odometer'] < upper_limit]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SzDZ1DGK6S4"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16,8))\n",
        "plt.subplot(2,2,1)\n",
        "sns.distplot(df['odometer'])\n",
        "plt.subplot(2,2,2)\n",
        "sns.boxplot(df['odometer'])\n",
        "plt.subplot(2,2,3)\n",
        "sns.distplot(ds_final['odometer'])\n",
        "plt.subplot(2,2,4)\n",
        "sns.boxplot(ds_final['odometer'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76P5yy6hR_ZO"
      },
      "source": [
        "If we try to remove the extra outliers for odometer there will be new one formed and a lot of data will be lost so we leave it\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkuwto-0SYyM"
      },
      "source": [
        "# **TAKING CARE OF NULL VALUES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2boGBp8TIdf"
      },
      "outputs": [],
      "source": [
        "ds=ds_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDq-jnTlSy40"
      },
      "outputs": [],
      "source": [
        "ds.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().mean().round(4).mul(100).sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "lOm1Sa0Hg6FM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16lRrcWMSbQw"
      },
      "outputs": [],
      "source": [
        "#Year is less so we'll drop that data and manufacturer\n",
        "ds = ds.dropna(axis=0, subset=['car_age', 'manufacturer'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7YOc2KPVL5x"
      },
      "source": [
        "We replace categorical values with MODE "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qA4CUeIgzcDM"
      },
      "outputs": [],
      "source": [
        "# Treating missing values of categorical variable by replacing it with MODE value\n",
        "ds['model'].fillna(value=ds['model'].mode()[0], inplace=True)\n",
        "ds['condition'].fillna(value=ds['condition'].mode()[0], inplace=True)\n",
        "ds['cylinders'].fillna(value=ds['cylinders'].mode()[0], inplace=True)\n",
        "ds['fuel'].fillna(value=ds['fuel'].mode()[0], inplace=True)\n",
        "ds['title_status'].fillna(value=ds['title_status'].mode()[0], inplace=True)\n",
        "ds['transmission'].fillna(value=ds['transmission'].mode()[0], inplace=True)\n",
        "ds['drive'].fillna(value=ds['drive'].mode()[0], inplace=True)\n",
        "ds['size'].fillna(value=ds['size'].mode()[0], inplace=True)\n",
        "ds['type'].fillna(value=ds['type'].mode()[0], inplace=True)\n",
        "ds['paint_color'].fillna(value=ds['paint_color'].mode()[0], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvBQuXLDwnOg"
      },
      "outputs": [],
      "source": [
        "ds.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV3ohgXPNecP"
      },
      "source": [
        "# **DATA ENCODING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3qNJbf_nM-L"
      },
      "source": [
        "- Converting all categorical columns to numeric using label encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lB43WNE4rOVy"
      },
      "outputs": [],
      "source": [
        "!pip install category_encoders\n",
        "import category_encoders as ce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pOGMN3ezL2e"
      },
      "outputs": [],
      "source": [
        "ds.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5vQxD4Irzst"
      },
      "outputs": [],
      "source": [
        "#Dataset=pd.get_dummies(Dataset,prefix=[ 'condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'size','type','state'],columns=['condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'size','type','state'])\n",
        "#Dataset=pd.get_dummies(Dataset,prefix=[ 'condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'size'],columns=['condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'size'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAXULx-vxvlT"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "ds['condition']=labelencoder.fit_transform(ds['condition'])\n",
        "ds['cylinders']=labelencoder.fit_transform(ds['cylinders'])\n",
        "ds['fuel']=labelencoder.fit_transform(ds['fuel'])\n",
        "ds['title_status']=labelencoder.fit_transform(ds['title_status'])\n",
        "ds['transmission']=labelencoder.fit_transform(ds['transmission'])\n",
        "ds['drive']=labelencoder.fit_transform(ds['drive'])\n",
        "ds['size']=labelencoder.fit_transform(ds['size'])\n",
        "ds['manufacturer']=labelencoder.fit_transform(ds['manufacturer'])\n",
        "ds['model']=labelencoder.fit_transform(ds['model'])\n",
        "ds['type']=labelencoder.fit_transform(ds['type'])\n",
        "ds['state']=labelencoder.fit_transform(ds['state'])\n",
        "ds['paint_color']=labelencoder.fit_transform(ds['paint_color'])\n",
        "ds_final=ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obKvdM65y7QK"
      },
      "outputs": [],
      "source": [
        "ds.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkkizWp-WTXC"
      },
      "source": [
        "# **FEATURE SELECTION**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the correlation matrix for the encoded data frame\n",
        "f, ax = plt.subplots(figsize=(12, 10))\n",
        "ax.set_title('Encoded Correlation Heatmap for Used Vehicles Dataset', pad=12)\n",
        "sns.heatmap(ds_final.corr(), vmin=-1, vmax=1, annot=True, cmap='Spectral')"
      ],
      "metadata": {
        "id": "BpbpJXeHHhYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2cf95ukl8hL"
      },
      "source": [
        "Selected columns are:'price','car_age','manufacturer','model','condition', 'cylinders','fuel','title_status','transmission','drive','size','type','state','paint_color'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuUHHShqmLwx"
      },
      "source": [
        "Final predictors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTbeosHTmNq6"
      },
      "outputs": [],
      "source": [
        "SelectedColumns=['price','car_age','manufacturer','model','condition', 'cylinders','fuel','title_status','transmission','drive','size','type','state','paint_color']\n",
        "# Selecting final columns\n",
        "Dataset=ds[SelectedColumns]\n",
        "Dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aH8RYNOmrbQ"
      },
      "outputs": [],
      "source": [
        "Dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNs3lfzfuU3C"
      },
      "outputs": [],
      "source": [
        "ds_final['odometer']=ds['odometer']\n",
        "ds_final['price']=ds['price']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kbY3YP_uDqa"
      },
      "source": [
        "# **SPLITTING THE DATA**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds.shape"
      ],
      "metadata": {
        "id": "O0Ei0we-3v9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZMI8KAqt8aQ"
      },
      "outputs": [],
      "source": [
        "ds_cols=ds_final.columns.tolist()\n",
        "ds_cols.remove('price')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DKA_DbIuMn4"
      },
      "outputs": [],
      "source": [
        "TargetVariable='price'\n",
        "Predictors=ds_cols\n",
        "\n",
        "X=ds_final[Predictors].values\n",
        "y=ds_final[TargetVariable].values\n",
        "\n",
        "# Split the data into training and testing set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNW9TPUxvC3y"
      },
      "source": [
        "# **STANDARDIZATION/NORMALIZATION OF DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG_mw69lvADg"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "PredictorScaler=MinMaxScaler()\n",
        "PredictorScalerFit=PredictorScaler.fit(X)\n",
        "X=PredictorScalerFit.transform(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpDiMxUj9PmM"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ilkf76w11b4"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th3Cw4CD1-8a"
      },
      "source": [
        "# **MODEL BUILDING:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5OiT7Ulv1VH"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as metrics\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reg_metrics(pred_model, x_train, x_test, y_train, y_test):\n",
        "  \n",
        "    y_pred = pred_model.predict(X_test)\n",
        "\n",
        "    # R² & Adjusted R²\n",
        "    print(\"\\n\\t--- Coefficient of Determination (R² & Adjusted R²) ---\")\n",
        "    r2 = metrics.r2_score(y_pred=y_pred, y_true=y_test)\n",
        "    adj_r2 = 1 - (1-r2)*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "\n",
        "    print(f\"R²\\t\\t: {round(r2, 2)}\")\n",
        "    print(f\"Adjusted R²\\t: {round(adj_r2, 2)}\")\n",
        "    \n",
        "\n",
        "    # MSE and RMSE\n",
        "    print(\"\\n\\t--- Mean Squared Error (MSE & RMSE) ---\")\n",
        "   \n",
        "    mse = metrics.mean_squared_error(y_pred=y_pred, y_true=y_test, squared=True)\n",
        "    rmse = metrics.mean_squared_error(y_pred=y_pred, y_true=y_test, squared=False)\n",
        "\n",
        "    print(f\"MSE\\t: {round(mse, 2)}\"+\"$\")\n",
        "    print(f\"RMSE\\t: {round(rmse, 2)}\"+\"$\")\n",
        "\n",
        "\n",
        "    # MAE\n",
        "    print(\"\\n\\t--- Mean Absolute Percentage Error (MAPE) ---\")\n",
        "    mape = np.mean(np.abs((y_test - y_pred)/y_test))*100\n",
        "    print(f\"MAPE\\t: {mape}\"+\"%\")\n",
        "\n",
        "    # Correlation Coefficient\n",
        "    print(\"\\n\\t--- Correlation Coefficient ---\")\n",
        "    corcoef = np.corrcoef(y_test, y_pred)\n",
        "    print(f\"Correlation coefficient\\t: {corcoef[0,1]}\")\n",
        "\n",
        "    #Accuracy\n",
        "    train_acc = round(pred_model.score(X_train, y_train)*100, 2)\n",
        "    test_acc = round(pred_model.score(X_test, y_test)*100, 2)\n",
        "\n",
        "    # Plot\n",
        "    print(\"\\t\")\n",
        "    x_ax = range(len(y_test))\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    print(plt.scatter(y_test, y_pred))\n",
        "    plt.title('Scatter plot')\n",
        "    plt.xlabel('Y Test Values')\n",
        "    plt.ylabel('Y predicted Values')\n",
        "    plt.show()\n",
        "\n",
        "    return (train_acc, test_acc)"
      ],
      "metadata": {
        "id": "YF6upMHpcYp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scatter_plot(axs, space=0.4):\n",
        "    def _show_on_single_plot(ax):        \n",
        "        for p in ax.patches:\n",
        "            _x = p.get_x() + p.get_width() / 2\n",
        "            _y = p.get_y() + p.get_height()\n",
        "            value = '{:.0f}'.format(p.get_height())\n",
        "            ax.text(_x, _y, value, ha=\"center\", va=\"bottom\")"
      ],
      "metadata": {
        "id": "6pJf998ts-E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_list = ['Linear Regression','Decision Trees', 'Bagging', 'Random Forest', 'Extra Tree' ,'XGBoost']\n",
        "acc_cols = ['Training Accuracy', 'Testing Accuracy']\n",
        "\n",
        "acc_df = pd.DataFrame(columns=acc_cols, index=models_list)\n",
        "\n",
        "acc_df.index.name='Models'"
      ],
      "metadata": {
        "id": "2QSV4ZTkcdG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression\n",
        "%%time\n",
        "linear_reg = LinearRegression()\n",
        "linear_reg.fit(X_train, y_train)\n",
        "print(\"\\t------- Linear Regression -------\")\n",
        "linreg_acc = reg_metrics(linear_reg, X_train, X_test, y_train, y_test)\n",
        "\n",
        "acc_df.loc['Linear Regression'] = linreg_acc\n"
      ],
      "metadata": {
        "id": "RSjp78i3cjrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree \n",
        "%%time\n",
        "dtree_reg = DecisionTreeRegressor()\n",
        "dtree_reg.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\t------- Decision Tree Regression -------\")\n",
        "dtree_acc = reg_metrics(dtree_reg, X_train, X_test, y_train, y_test)\n",
        "\n",
        "acc_df.loc['Decision Trees'] = dtree_acc"
      ],
      "metadata": {
        "id": "F3Y-smZtcmv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bagging\n",
        "%%time\n",
        "bag_reg = BaggingRegressor()\n",
        "bag_reg.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\t------- Bagging -------\")\n",
        "bag_acc = reg_metrics(bag_reg, X_train, X_test, y_train, y_test)\n",
        "\n",
        "acc_df.loc['Bagging'] = bag_acc"
      ],
      "metadata": {
        "id": "r-8jXsorcrKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Regression\n",
        "%%time\n",
        "rf_reg = RandomForestRegressor(n_estimators = 50,oob_score = True,n_jobs = -1,random_state =1)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\t------- Random Forest Regression -------\")\n",
        "rf_acc = reg_metrics(rf_reg, X_train, X_test, y_train, y_test)\n",
        "\n",
        "acc_df.loc['Random Forest'] = rf_acc"
      ],
      "metadata": {
        "id": "8rluLBCbcujw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extra-Tree\n",
        "%%time\n",
        "etr_reg = ExtraTreesRegressor(n_estimators = 50,n_jobs = -1,random_state =1)\n",
        "etr_reg.fit(X_train,y_train)\n",
        "\n",
        "print(\"\\t------- Extra Tree Regression -------\")\n",
        "etr_acc = reg_metrics(etr_reg, X_train, X_test, y_train, y_test)\n",
        "\n",
        "acc_df.loc['Extra Tree'] = etr_acc"
      ],
      "metadata": {
        "id": "NLAaL49rmHCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost\n",
        "%%time\n",
        "#xgb_reg = xgb.XGBRegressor(n_estimators = 50,oob_score = True,n_jobs = -1,random_state =1) \n",
        "xgb_reg=xgb.XGBRegressor(eta=0.05,max_depth=7,n_estimators=200)\n",
        "xgb_reg.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\t------- XGBoost Regression -------\")\n",
        "xgb_acc = reg_metrics(xgb_reg, X_train, X_test, y_train, y_test)\n",
        "\n",
        "acc_df.loc['XGBoost'] = xgb_acc"
      ],
      "metadata": {
        "id": "i5UOr7Cycwr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_df.astype(str) + '%'"
      ],
      "metadata": {
        "id": "7km2dQpNc1aH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_df.columns=['Training','Testing']\n",
        "acc_plot_df = acc_df.reset_index().melt(id_vars=['Models'])\n",
        "acc_plot_df.columns=['Models','Dataset','Accuracy']\n",
        "\n",
        "#Plot \n",
        "f, ax = plt.subplots(figsize=(12, 8))\n",
        "sns.barplot(x=\"Models\", y=\"Accuracy\", hue=\"Dataset\", data=acc_plot_df, palette=\"Blues_d\")\n",
        "ax.set_title(\"Accuracies by Models\", pad=12)"
      ],
      "metadata": {
        "id": "kYYQC7O7dR_M"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "wVg6vOyRRWvO",
        "mdxZjZSnvbyQ",
        "t8EGp_TtwHaR",
        "w2Xeb1UQBuJY",
        "zoZwsh4xFiDq",
        "tkuwto-0SYyM",
        "UV3ohgXPNecP",
        "GkkizWp-WTXC",
        "6kbY3YP_uDqa",
        "pNW9TPUxvC3y"
      ],
      "name": "Used_car_price_prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}